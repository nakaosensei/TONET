# Esse projeto √© uma implementa√ß√£o particular do artigo TONet: A Fast and Efficient Method for Traffic Obfuscation Using Adversarial Machine Learning
Esta p√°gina apresenta um c√≥digo que implementa os mecanismos propostos no artigo 'TONet: A Fast and Efficient Method for Traffic Obfuscation Using Adversarial Machine Learning', publicado em novembro de 2022.

O artigo prop√µe uma abordagem fazendo uso redes neurais adversariais visando ofuscar o tr√°fego de dispositivos conectados na Internet, os dados ofuscados pela solu√ß√£o s√£o provados em redes neurais artificiais com altas taxas de sucesso na identifica√ß√£o de dispostivos.

Esse projeto cont√©m o c√≥digo fonte para a reprodu√ß√£o do trabalho, para o executar √© preciso fazer o download das bases de dados e arquivos adicionais.

# Download das bases de dados e estrutura adicional
Fa√ßa o download do arquivo dispon√≠vel em:
https://drive.google.com/file/d/1o0aA9w9pNsOWlss5IAfjcX046P3JJhUS/view?usp=sharing

Ao extrair os arquivos zipados, voc√™ ver√° a seguinte estrutura de pastas:
- üìÇ data (Cont√©m as bases de dados carregadas)
- üìÇ inputs (Arquivos com informa√ß√µes sobre caracter√≠sticas da base de dados)
- üìÇ outputs (Arquivos gerados, exemplos adversariais ficam aqui)
- üìÇ inst-bibliotecas (Depend√™ncias do projeto)
- üìÇ savedModels (Redes neurais salvas)
- üìÇ src (Diret√≥rio de c√≥digo do projeto, fa√ßa o git clone dentro do diret√≥rio src)

Uma vez que os arquivos estiverem descompactados em sua m√°quina, acesse o diret√≥rio src e executa o comando:
git clone https://github.com/nakaosensei/TONET

Alternativamente, voc√™ pode baixar um zip completo (com o diret√≥rio src j√° incluso) em:
https://drive.google.com/file/d/1vYwJ6hfaFKVsanDoa7pRFabRr2JPphxI/view?usp=drive_link


# Guia r√°pido de instala√ß√£o de dependencias
Para instala√ß√£o das bibliotecas necess√°rias, acesse a pasta **inst-bibliotecas** e execute o comando:

Comando: sudo ./downloadLibraries.sh

# Guia de execu√ß√£o
O primeiro passo importante √© gerar a rede neural que ser√° usada na cria√ß√£o das amostras adversarias, para isso, invoque o script:
```bash
python3 neuralNetworkGenerator.py
```
Ele ir√° treinar a rede neural que ser√° usada para gerar os exemplos advers√°riais e salvar o resultado em ../savedModels/trainedTonet.

Ap√≥s isso, precisaremos treinar um poss√≠vel atacante com base nos dados originais, deixamos de exemplo uma rede neural de tr√™s camadas, para treinar esse modelo atacante disponibilizado, invoque:
```bash
python3 python3 attackerNN.py
```
Ele ir√° treinar a rede neural que tentar√° realizar a classifica√ß√£o dos dados e salvar o resultado em ../savedModels/attackerModelWeka.

Agora basta gerar exemplos adversariais atrav√©s da rede artificial gerada, utilize o script:
```bash
python3 adversarialExamplesGenerator.py
```
Na pr√°tica, o script adversarialExamplesGenerator.py utiliza a rede neural pr√© treinada (que est√° no diret√≥rio ../savedModels/trainedTonet) para gerar as asmostras adversariais e salvar em ../../outputs/adversarialExamples e ../../outputs/targets


Finalmente, para realizar o teste das amostras, use o seguinte script:
```bash
python3 adversarialExamplesTest.py
```

O script adversarialExamplesTest √© quem de fato realiza o teste das amostras advers√°riais contra um potencial classificador atacante, o script automaticamente invocar√° a rede neural atacante salva em (../savedModels/attackerModelWeka) com as amostras geradas, para isso, ele realiza testes com:
- Dados reais somente 
- Dados reais + 5% da base amostras advers√°rias
- Dados reais + 10% da base amostras advers√°rias
- Dados reais + 15% da base amostras advers√°rias
- Dados reais + 25% da base amostras advers√°rias
- Dados reais + 50% da base amostras advers√°rias
- Dados reais + 75% da base amostras advers√°rias
- Dados reais + 90% da base amostras advers√°rias


Para gerar os exemplos adversariais de maneira estoc√°stica, use:
```bash
python3 stochasticAdversarialGenerator.py
```
O script stochasticAdversarialGenerator.py tenta gerar exemplos adversariais de maneira intuitiva, de modo a gerar pequenas oscila√ß√µes pelo produto das grandesas dos dados originais por constantes pr√©-definidas, as amostras adversariais estoc√°sticas s√£o salvas nos diret√≥rios ../../outputs/stochasticAdversarialExamples e ../../outputs/stochasticTargets

No momento, o teste das amostras estoc√°sticas est√° fazendo a verifica√ß√£o considerando somente a rede neural treinada (../savedModels/trainedTonet) e os exemplos adversariais gerados como teste. Para testar as amostras geradas, use:
```bash
python3 stochasticAdversarialTester.py
```

Como b√¥nus, foram realizados testes com outras configura√ß√µes de redes neurais e do classificar k-NN sobre os dados originais, para os invocar, use:
```bash

python3 knnTester.py
```



