# Esse projeto √© uma implementa√ß√£o particular do artigo TONet: A Fast and Efficient Method for Traffic Obfuscation Using Adversarial Machine Learning
Esta p√°gina apresenta um c√≥digo que implementa os mecanismos propostos no artigo 'TONet: A Fast and Efficient Method for Traffic Obfuscation Using Adversarial Machine Learning', publicado em novembro de 2022.

O artigo prop√µe uma abordagem fazendo uso redes neurais adversariais visando ofuscar o tr√°fego de dispositivos conectados na Internet, os dados ofuscados pela solu√ß√£o s√£o provados em redes neurais artificiais com altas taxas de sucesso na identifica√ß√£o de dispostivos.

Esse projeto cont√©m o c√≥digo fonte para a reprodu√ß√£o do trabalho, para o executar √© preciso fazer o download das bases de dados e arquivos adicionais.

# Download das bases de dados e estrutura adicional
Fa√ßa o download do arquivo dispon√≠vel em:
https://drive.google.com/file/d/1o0aA9w9pNsOWlss5IAfjcX046P3JJhUS/view?usp=sharing

Ao extrair os arquivos zipados, voc√™ ver√° a seguinte estrutura de pastas:
- üìÇ data (Cont√©m as bases de dados carregadas)
- üìÇ inputs (Arquivos com informa√ß√µes sobre caracter√≠sticas da base de dados)
- üìÇ outputs (Arquivos gerados, exemplos adversariais ficam aqui)
- üìÇ inst-bibliotecas (Depend√™ncias do projeto)
- üìÇ savedModels (Redes neurais salvas)
- üìÇ src (Diret√≥rio de c√≥digo do projeto, fa√ßa o git clone dentro do diret√≥rio src)

Uma vez que os arquivos estiverem descompactados em sua m√°quina, acesse o diret√≥rio src e executa o comando:
git clone https://github.com/nakaosensei/TONET.

Alternativamente, voc√™ pode baixar um zip completo (com o diret√≥rio src j√° incluso) em:
https://drive.google.com/file/d/1vYwJ6hfaFKVsanDoa7pRFabRr2JPphxI/view?usp=drive_link


# Guia r√°pido de instala√ß√£o de dependencias
Para instala√ß√£o das bibliotecas necess√°rias, acesse a pasta **inst-bibliotecas** e execute o comando:

Comando: sudo ./downloadLibraries.sh




# Guia de execu√ß√£o
O primeiro passo importante √© gerar os exemplos adversariais, no momento, o TONet √© capaz de realizar essa tarefa de duas maneiras:
- Atrav√©s de uma rede neural artificial
- Estocasticamente

Para gerar exemplos adversariais atrav√©s da rede artificial, utilize o script:
```bash
python3 adversarialExamplesGenerator.py
```
E depois de gerar, voc√™ realizar o teste dessas amostras:
```bash
python3 adversarialExamplesTest.py
```
Na pr√°tica, o script adversarialExamplesGenerator.py utiliza a rede neural pr√© treinada (que est√° no diret√≥rio ../savedModels/trainedTonet) para gerar as asmostras adversariais e salvar em ../../outputs/adversarialExamples e ../../outputs/targets


O script adversarialExamplesTest √© quem de fato realiza o teste da rede neural (../savedModels/trainedTonet) com as amostras geradas, para isso, ele realiza testes com:
- Dados reais somente (../outputs/originalDatabaseSamples e ../outputs/originalDatabaseTargets)
- Dados reais + 5% de amostras adversarias (../outputs/datasetMixedSamples5 e ../outputs/datasetMixedTargets5)
- Dados reais + 10% de amostras adversarias (../outputs/datasetMixedSamples10 e ../outputs/datasetMixedTargets10)
- Dados reais + 15% de amostras adversarias (../outputs/datasetMixedSamples15 e ../outputs/datasetMixedTargets15)
- Dados reais + 25% de amostras adversarias (../outputs/datasetMixedSamples25 e ../outputs/datasetMixedTargets25)
- Dados reais + 50% de amostras adversarias (../outputs/datasetMixedSamples50 e ../outputs/datasetMixedTargets50)

Os resultados s√£o ent√£o impressos na tela, e tamb√©m escritos no arquivo tests.txt

Adicionalmente, existe um script que executa o mesmo experimento, mas fazendo o carregamento dos pacotes em propor√ß√£o somente com base nos dados originais e nos arquivos em ../../outputs/adversarialExamples e ../../outputs/targets, esse script √©:
```bash
python3 dualAdversarialDataSetTester.py
```

Para gerar os exemplos adversariais de maneira estoc√°stica, use:
```bash
python3 stochasticAdversarialGenerator.py
```
O script stochasticAdversarialGenerator.py tenta gerar exemplos adversariais de maneira intuitiva, de modo a gerar pequenas oscila√ß√µes pelo produto das grandesas dos dados originais por constantes pr√©-definidas, as amostras adversariais estoc√°sticas s√£o salvas nos diret√≥rios ../../outputs/stochasticAdversarialExamples e ../../outputs/stochasticTargets


No momento, o teste das amostras estoc√°sticas est√° fazendo a verifica√ß√£o considerando somente a rede neural treinada (../savedModels/trainedTonet) e os exemplos adversariais gerados como teste. Para testar as amostras geradas, use:
```bash
python3 stochasticAdversarialTester.py
```

At√© aqui foram apresentados os scripts necess√°rios para gerar e testar as amostras adversariais, mas existem mais opera√ß√µes poss√≠veis, por exemplo, para treinar uma rede neural que ser√° usada para gerar as amostras adversarias, use script:
```bash
python3 tonetNN.py
```

Como b√¥nus, foram realizados testes com outras configura√ß√µes de redes neurais e do classificar k-NN sobre os dados originais, para os invocar, use:
```bash
python3 attackerNN.py
python3 knnTester.py
```



